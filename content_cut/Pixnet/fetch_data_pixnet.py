#å°‡ç—å®¢é‚¦è³‡æ–™ä¸­ã€ attributes ã€çš„ã€ CSV ã€è½‰å‹æˆã€ json  ã€æ ¼å¼
def convert_to_json_attributes(file_name):
    count = 1
    dict_list = dict()

    #å°‡ã€ key ã€è¨­æˆã€ ç¬¬ X ç­† ã€
    with open(file_name,"r") as pixnet_file :
        pixnet_data = csv.DictReader(pixnet_file)

        #å°‡åŸå§‹æª”æ¡ˆä¸­çš„æ¯è¡Œè³‡æ–™è®€é€²æ¯å€‹ key æˆç‚º value å€¼
        for line in pixnet_data:
            dict_list["ç¬¬"+str(count)+"ç­†"] = dict()
            for key,value in line.items() :
                dict_list["ç¬¬"+str(count)+"ç­†"][key] = value
            count = count + 1

    #æœ€å¾Œå°‡çµæœå­˜æˆä¸€å€‹æ–°çš„æª”ï¼Œä¸¦é‡æ–°å‘½å
    with open ( "converted_pixnet_data/"+file_name[17:-4]+".json" ,"w") as file_converted :
        file_converted.write(json.dumps(dict_list,ensure_ascii=False,indent=4))
        file_converted.close()

#å°‡ç—å®¢é‚¦è³‡æ–™ä¸­ã€ content ã€çš„ã€ CSV ã€è½‰å‹æˆã€ json  ã€æ ¼å¼
def convert_to_json_content(file_name):
    count = 1
    dict_list = dict()

    #å°‡ã€ key ã€è¨­æˆã€ ç¬¬ X ç­† ã€
    with open(file_name,"r") as pixnet_file :
        pixnet_data = csv.DictReader(pixnet_file)

        #å°‡åŸå§‹æª”æ¡ˆä¸­çš„æ¯è¡Œè³‡æ–™è®€é€²æ¯å€‹ key æˆç‚º value å€¼
        for line in pixnet_data:
            dict_list["ç¬¬"+str(count)+"ç­†"] = dict()
            for key,value in line.items() :
                dict_list["ç¬¬"+str(count)+"ç­†"][key] = value
            count = count + 1

    #æœ€å¾Œå°‡çµæœå­˜æˆä¸€å€‹æ–°çš„æª”ï¼Œä¸¦é‡æ–°å‘½å
    with open ( "converted_pixnet_data/"+file_name[14:-4]+".json" ,"w") as file_converted :
        file_converted.write(json.dumps(dict_list,ensure_ascii=False,indent=4))
        file_converted.close()

#å–å¾—ã€ attributes json ã€æª”æ¡ˆçš„è³‡æ–™ï¼Œä¸¦ã€ load ã€é€²ä¾†å¾Œï¼Œåšæ–·è©ï¼Œä¸”å°‡çµ±è¨ˆæ–·è©å¾Œçš„çµæœï¼Œå€‹åˆ¥å­˜æˆæ–°æª”
def fetch_data_attributes(file_name):
    with open(file_name,"r") as pixnet_file :

        #è®€æª”æ¡ˆ
        pixnet_data = json.loads(pixnet_file.read())

        #å°‡è³‡æ–™æ–·è©
        jieba_cut_attributes(pixnet_data,"title")

        #å¦å­˜æ–°æª”
        save_file(file_name,count_data,"title")

##å–å¾—ã€ content json ã€æª”æ¡ˆçš„è³‡æ–™ï¼Œä¸¦ã€ load ã€é€²ä¾†å¾Œï¼Œåšæ–·è©ï¼Œä¸”å°‡çµ±è¨ˆæ–·è©å¾Œçš„çµæœï¼Œå€‹åˆ¥å­˜æˆæ–°æª”
def fetch_data_content(file_name):
    with open(file_name,"r") as pixnet_file :

        #è®€æª”æ¡ˆ
        pixnet_data = json.loads(pixnet_file.read())

        #å°‡è³‡æ–™æ–·è©
        jieba_cut_content(pixnet_data,"content")

        #å¦å­˜æ–°æª”
        save_file(file_name,count_data,"content")

#å°ˆé–€è™•ç† attributes_after çš„ json è³‡æ–™
def fetch_data_content_after(content_file_name,attr_file_name):
    pixnet_attr = dict()
    pixnet_content = dict()

    #æ‰“é–‹ attributes_afterï¼ŒæŠ“å‡ºè³‡æ–™
    with open(attr_file_name,"r") as pixnet_attr_file:

        #è®€æª”æ¡ˆ
        pixnet_attr = json.loads(pixnet_attr_file.read())

    #æ‰“é–‹ contentï¼ŒæŠ“å‡ºè³‡æ–™
    with open(content_file_name,"r") as pixnet_content_file :

        #è®€æª”æ¡ˆ
        pixnet_content = json.loads(pixnet_content_file.read())

    #å°‡ attributes è·Ÿ content æª”æ¡ˆé€²è¡Œæ¯”å°
    final_match = match_content(pixnet_attr,pixnet_content)

    #å°‡è³‡æ–™æ–·è©
    jieba_cut_content(final_match,"content")

    #å¦å­˜æ–°æª”
    save_file(content_file_name,count_data,"content")

#æ¯”å°è³‡æ–™ï¼ŒæŠŠç¬¦åˆ filter_after json æª”çš„ content è³‡æ–™æŠ“å‡ºä¾†ï¼Œä¸Ÿé€²ä¸€å€‹ dict ï¼Œä¸¦å›å‚³
def match_content(pixnet_attr,pixnet_content):
    final_match = dict()
    for attr_key,attr_value in pixnet_attr.items():
        for content_key,content_value in pixnet_content.items():
            if attr_key == content_key :
                final_match[attr_key] = content_value
                print(attr_key + " : {")
                print(content_value)
                print("}")
                break
    return final_match

#å°‡ã€ attributes ã€çš„è³‡æ–™é€²è¡Œæ–·è©
def jieba_cut_attributes(each_kinds,name):
    segment = str()

    #å°‡æ¨™é»ç¬¦è™Ÿæˆ–æ˜¯ä¸å¿…è¦çš„å­—åˆ—æˆå­—ä¸²ï¼Œæ¯ç­†æ–‡å­—è³‡æ–™å°‡èˆ‡ä¹‹ä½œæ¯”å°
    punctuations = '''ã€‚ğŸ¤“ğŸ»!ï¼^___^â€¦â€¦~ï¼Œ()-[]{};:'"\,<>./?ï¼Ÿï¼ã€‚ã€ï¼ @#$%^&* ï¼ï¼ˆï¼‰ï¼š=_~â¤ï¸ğŸ˜…à¹‘ãƒ»Ï‰ï½â™¥â€3ğŸ˜±ğŸ˜³ğŸ˜†â¤ğŸ˜ğŸ’ªğŸ¼ğŸ¤£ğŸ˜ŠğŸ˜£ğŸ˜‚ğŸ’ªğŸ˜ğŸ˜ğŸ‘ğŸ‘ğŸ˜”01234566789çš„äº†å—æˆ‘ä½ æ˜¯è¦å»éƒ½å°±ä¹Ÿèˆ‡åœ¨å¾ˆä¸åˆ°åƒæœƒå¥½åˆ°æœ‰å€‘è·Ÿå¾Œäººå’Œæƒ³ä¸Š'''
    punctuations += "ã‚ã„ã†ãˆãŠã‹ããã‘ã“ã•ã—ã™ã›ããŸã¡ã¤ã¦ã¨ãªã«ã¬ã­ã®ã¯ã²ãµã¸ã»ã¾ã¿ã‚€ã‚ã‚‚ã‚„ã‚†ã‚ˆã‚ã‚’ã‚“ãŒããã’ã”ã–ã˜ãšãœãã ã¢ãšã§ã©ã°ã³ã¶ã¹ã¼ã±ã´ã·ãºã½ãã‚ƒãã‚…ãã‚‡ãã‚ƒãã‚…ãã‚‡ã—ã‚ƒã—ã‚…ã—ã‚‡ã˜ã‚ƒã˜ã‚…ã˜ã‚‡ã¡ã‚ƒã¡ã‚…ã¡ã‚‡ã«ã‚ƒã«ã‚…ã«ã‚‡ã²ã‚ƒã²ã‚…ã²ã‚‡ã³ã‚ƒã³ã‚…ã³ã‚‡ã´ã‚ƒã´ã‚…ã´ã‚‡ã¿ã‚ƒã¿ã‚…ã¿ã‚‡ã‚Šã‚ƒã‚Šã‚…ã‚Šã‚‡"
    punctuations += "ã‚¢ã‚¤ã‚¦ã‚¨ã‚ªã‚«ã‚­ã‚¯ã‚±ã‚³ã‚µã‚·ã‚¹ã‚»ã‚½ã‚¿ãƒãƒ„ãƒ†ãƒˆãƒŠãƒ‹ãƒŒãƒãƒãƒãƒ’ãƒ•ãƒ˜ãƒ›ãƒãƒŸãƒ ãƒ¡ãƒ¢ãƒ¤ãƒ¦ãƒ¨ãƒ¯ãƒ²ãƒ³ã‚¬ã‚®ã‚°ã‚²ã‚´ã‚¶ã‚¸ã‚ºã‚¼ã‚¾ãƒ€ãƒ‚ã‚ºãƒ‡ãƒ‰ãƒãƒ“ãƒ–ãƒ™ãƒœãƒ‘ãƒ”ãƒ—ãƒšãƒã‚­ãƒ£ã‚­ãƒ¥ã‚­ãƒ§ã‚®ãƒ£ã‚®ãƒ¥ã‚®ãƒ§ã‚·ãƒ£ã‚·ãƒ¥ã‚·ãƒ§ã‚¸ãƒ£ã‚¸ãƒ¥ã‚¸ãƒ§ãƒãƒ£ãƒãƒ¥ãƒãƒ§ãƒ‹ãƒ£ãƒ‹ãƒ¥ãƒ‹ãƒ§ãƒ’ãƒ£ãƒ’ãƒ¥ãƒ’ãƒ§ãƒ“ãƒ£ãƒ“ãƒ¥ãƒ“ãƒ§ãƒ”ãƒ£ãƒ”ãƒ¥ãƒ”ãƒ§ãƒŸãƒ£ãƒŸãƒ¥ãƒŸãƒ§ãƒªãƒ£ãƒªãƒ¥ãƒªãƒ§"
    punctuations += "ãƒ´ã‚‹ã£ã‚Œã‚‰ã‚Ã¼ãƒ«ãƒ©ãƒ¶ãƒ¬ãˆ±ãƒƒã‚¡ã€‘Ã—ã‚£\\n"
    punctuations += "ã€ ã€ã€ã€Œã€ï¼ˆï¼‰ï¼Œã€‚ï¼›ã€ï¼Ÿï¼…ï¸¿ï¼†ï¼Šï¼„ï¼ƒï¼ ï¼ ï¼ï½â€”ï½œï¼¼"
    punctuations += "abcdefghijklmnopqrstuvwxyz"

    #ä¾åºè™•ç†æ¯ç­†è³‡æ–™
    for each_id,each_content in each_kinds.items() :
        for small_title , small_content in each_content.items() :

            #è™•ç†ã€ key ã€ç‚º title çš„ value å€¼
            if small_title == name :
                segment = ""
                no_punct = ""
                content = small_content

                #å¦‚æœ content ç‚º Noneï¼Œå‰‡çµ¦äºˆç©ºå€¼
                if content == None :
                    segment = ""
                else :

                    #æª¢æŸ¥å€¼è£¡é¢æœ‰æ²’æœ‰ punctuations
                    for char in content:
                       if char not in punctuations:
                           no_punct = no_punct + char

                    #å°‡ç¯©é¸éå­—å¥çš„çµæœé€²è¡Œæ–·è©
                    segment = jieba.cut(no_punct, cut_all=False)
            else :
                pass

            #å°‡æ–·è©çµæœçµ±è¨ˆä¸¦å­˜åœ¨ dict è£¡é¢
            check_count(segment,name)

#å°‡ã€ content ã€çš„è³‡æ–™é€²è¡Œæ–·è©
def jieba_cut_content(each_kinds,name):
    segment = str()

    #å°‡æ¨™é»ç¬¦è™Ÿæˆ–æ˜¯ä¸å¿…è¦çš„å­—åˆ—æˆå­—ä¸²ï¼Œæ¯ç­†æ–‡å­—è³‡æ–™å°‡èˆ‡ä¹‹ä½œæ¯”å°
    punctuations = '''ã€‚ğŸ¤“ğŸ»!ï¼^___^â€¦â€¦~ï¼Œ()-[]{};:'"\,<>./?ï¼Ÿï¼ã€‚ã€ï¼ @#$%^&* ï¼ï¼ˆï¼‰ï¼š=_~â¤ï¸ğŸ˜…à¹‘ãƒ»Ï‰ï½â™¥â€3ğŸ˜±ğŸ˜³ğŸ˜†â¤ğŸ˜ğŸ’ªğŸ¼ğŸ¤£ğŸ˜ŠğŸ˜£ğŸ˜‚ğŸ’ªğŸ˜ğŸ˜ğŸ‘ğŸ‘ğŸ˜”01234566789çš„äº†å—æˆ‘ä½ æ˜¯è¦å»éƒ½å°±ä¹Ÿèˆ‡åœ¨å¾ˆä¸åˆ°åƒæœƒå¥½åˆ°æœ‰å€‘è·Ÿå¾Œäººå’Œæƒ³ä¸Š'''
    punctuations += "ã‚ã„ã†ãˆãŠã‹ããã‘ã“ã•ã—ã™ã›ããŸã¡ã¤ã¦ã¨ãªã«ã¬ã­ã®ã¯ã²ãµã¸ã»ã¾ã¿ã‚€ã‚ã‚‚ã‚„ã‚†ã‚ˆã‚ã‚’ã‚“ãŒããã’ã”ã–ã˜ãšãœãã ã¢ãšã§ã©ã°ã³ã¶ã¹ã¼ã±ã´ã·ãºã½ãã‚ƒãã‚…ãã‚‡ãã‚ƒãã‚…ãã‚‡ã—ã‚ƒã—ã‚…ã—ã‚‡ã˜ã‚ƒã˜ã‚…ã˜ã‚‡ã¡ã‚ƒã¡ã‚…ã¡ã‚‡ã«ã‚ƒã«ã‚…ã«ã‚‡ã²ã‚ƒã²ã‚…ã²ã‚‡ã³ã‚ƒã³ã‚…ã³ã‚‡ã´ã‚ƒã´ã‚…ã´ã‚‡ã¿ã‚ƒã¿ã‚…ã¿ã‚‡ã‚Šã‚ƒã‚Šã‚…ã‚Šã‚‡"
    punctuations += "ã‚¢ã‚¤ã‚¦ã‚¨ã‚ªã‚«ã‚­ã‚¯ã‚±ã‚³ã‚µã‚·ã‚¹ã‚»ã‚½ã‚¿ãƒãƒ„ãƒ†ãƒˆãƒŠãƒ‹ãƒŒãƒãƒãƒãƒ’ãƒ•ãƒ˜ãƒ›ãƒãƒŸãƒ ãƒ¡ãƒ¢ãƒ¤ãƒ¦ãƒ¨ãƒ¯ãƒ²ãƒ³ã‚¬ã‚®ã‚°ã‚²ã‚´ã‚¶ã‚¸ã‚ºã‚¼ã‚¾ãƒ€ãƒ‚ã‚ºãƒ‡ãƒ‰ãƒãƒ“ãƒ–ãƒ™ãƒœãƒ‘ãƒ”ãƒ—ãƒšãƒã‚­ãƒ£ã‚­ãƒ¥ã‚­ãƒ§ã‚®ãƒ£ã‚®ãƒ¥ã‚®ãƒ§ã‚·ãƒ£ã‚·ãƒ¥ã‚·ãƒ§ã‚¸ãƒ£ã‚¸ãƒ¥ã‚¸ãƒ§ãƒãƒ£ãƒãƒ¥ãƒãƒ§ãƒ‹ãƒ£ãƒ‹ãƒ¥ãƒ‹ãƒ§ãƒ’ãƒ£ãƒ’ãƒ¥ãƒ’ãƒ§ãƒ“ãƒ£ãƒ“ãƒ¥ãƒ“ãƒ§ãƒ”ãƒ£ãƒ”ãƒ¥ãƒ”ãƒ§ãƒŸãƒ£ãƒŸãƒ¥ãƒŸãƒ§ãƒªãƒ£ãƒªãƒ¥ãƒªãƒ§"
    punctuations += "ãƒ´ã‚‹ã£ã‚Œã‚‰ã‚Ã¼ãƒ«ãƒ©ãƒ¶ãƒ¬ãˆ±ãƒƒã‚¡ã€‘Ã—ã‚£\\n"
    punctuations += "ã€ ã€ã€ã€Œã€ï¼ˆï¼‰ï¼Œã€‚ï¼›ã€ï¼Ÿï¼…ï¸¿ï¼†ï¼Šï¼„ï¼ƒï¼ ï¼ ï¼ï½â€”ï½œï¼¼"
    punctuations += "abcdefghijklmnopqrstuvwxyz"

    #ä¾åºè™•ç†æ¯ç­†è³‡æ–™
    for each_id,each_content in each_kinds.items() :
        for small_title , small_content in each_content.items() :

            #è™•ç†ã€ key ã€ç‚º title çš„ value å€¼
            if small_title == name :
                segment = ""
                no_punct = ""

                #ç”¨ beautiful soup å°‡ content ä¸­çš„ html æ–‡å­— parse æˆ hmtl tag
                soup = BeautifulSoup(small_content, 'html.parser')

                #æ‰¾åˆ°æ‰€æœ‰å«æœ‰ã€ span ã€tag çš„æ–‡å­—ã€å­—å¥
                content_span = soup.find_all('span')

                #æ‰¾åˆ°æ‰€æœ‰å«æœ‰ã€ p ã€tag çš„æ–‡å­—ã€å­—å¥
                content_p = soup.find_all('p')

                #æ‰¾åˆ°æ‰€æœ‰å«æœ‰ã€ strong ã€tag çš„æ–‡å­—ã€å­—å¥
                content_strong = soup.find_all('strong')

                #ä¾åºæ‰¾æ‰€æœ‰å«æœ‰ã€ span ã€tag çš„æ–‡å­—ã€å­—å¥
                for span in content_span:
                    content = span.text
                    print(content)

                    #å¦‚æœ content ç‚º Noneï¼Œå‰‡çµ¦äºˆç©ºå€¼
                    if content == None :
                        segment = ""
                    else :

                        #æª¢æŸ¥å€¼è£¡é¢æœ‰æ²’æœ‰ punctuations
                        for char in content:
                           if char not in punctuations:
                               no_punct = no_punct + char

                #ä¾åºæ‰¾æ‰€æœ‰å«æœ‰ã€ p ã€tag çš„æ–‡å­—ã€å­—å¥
                for p in content_p:
                    content = p.text
                    print(content)

                    #å¦‚æœ content ç‚º Noneï¼Œå‰‡çµ¦äºˆç©ºå€¼
                    if content == None :
                        segment = ""
                    else :

                        #æª¢æŸ¥å€¼è£¡é¢æœ‰æ²’æœ‰ punctuations
                        for char in content:
                           if char not in punctuations:
                               no_punct = no_punct + char

                #ä¾åºæ‰¾æ‰€æœ‰å«æœ‰ã€ strong ã€tag çš„æ–‡å­—ã€å­—å¥
                for strong in content_strong:
                    content = strong.text
                    print(content)

                    #å¦‚æœ content ç‚º Noneï¼Œå‰‡çµ¦äºˆç©ºå€¼
                    if content == None :
                        segment = ""
                    else :

                        #æª¢æŸ¥å€¼è£¡é¢æœ‰æ²’æœ‰ punctuations
                        for char in content:
                           if char not in punctuations:
                               no_punct = no_punct + char

                #å°‡è©²æ®µå…§å®¹ç¯©é¸éå¾Œä¸” parse éå¾Œçš„æ–‡å­—è³‡æ–™é€²è¡Œæ–·è©
                segment = jieba.cut(no_punct, cut_all=False)
            else :
                pass

            #å°‡æ–·è©çµæœçµ±è¨ˆä¸¦å­˜åœ¨ dict è£¡é¢
            check_count(segment,name)

#å°‡æ–·å®Œè©å¾Œçš„çµæœï¼Œé€²è¡Œçµ±è¨ˆï¼Œå­˜åœ¨ã€ count_data ã€çš„ dict è£¡é¢
def check_count(segment,name):
    global count_data
    for x in segment:

        #è‹¥ä¸€é–‹å§‹ä¸åœ¨å­—å…¸å…§ï¼Œå‰‡çµ¦äºˆåˆå§‹å€¼
        if x not in count_data:
            count_data[x] = 1

        #è‹¥åœ¨å­—å…¸å…§ï¼Œå‰‡é€²è¡Œç´¯åŠ 
        else:
            count = count_data.get(x)
            count_data[x] = count + 1

#å°‡ count_data çš„ json å­˜æˆå­—å…¸æ ¼å¼
def save_file(file_name,data,name):

    #å°‡ count_data ä¸­ï¼Œæ•¸é‡å°‘æ–¼ 10 çš„è³‡æ–™åˆªæ‰
    #for key, value in data.copy().items():
    #    if int(value) < 10:
    #        del data[key]

    #æœ€å¾Œå°‡çµæœå­˜æˆä¸€å€‹æ–°çš„æª”ï¼Œä¸¦é‡æ–°å‘½å
    with open ( "Pixnet_data_count/" + file_name[22:-5] + "_count_jieba_after.json","w") as count :
        ordered_data = sorted(data.items(), key=lambda x:(-x[1], x[0]))
        count.write(json.dumps(OrderedDict(ordered_data),ensure_ascii=False,indent=4))
        count.close()

    #å°‡ count_data é‡æ–°é¸å‘Šç‚ºç©ºå­—å…¸
    count_data = dict()

#å¼•é€²ç›¸é—œæœƒç”¨åˆ°çš„å‡½å¼åº«
import csv,json,jieba,facebook,re,glob,sys
from collections import OrderedDict
from bs4 import BeautifulSoup
if __name__ == "__main__":

    #å»ºç«‹è©åº«ï¼ˆå­—å…¸ï¼‰
    jieba.set_dictionary("data/dict.txt.big")
    jieba.load_userdict("data/userdict.txt")

    #è®“ã€ å¤§é‡ ã€è³‡æ–™å¯ä»¥è®€
    csv.field_size_limit(sys.maxsize)

    # file name and dataset here
    attributes_filename = "pixnet_attributes/*.csv"
    attributes_each = glob.glob(attributes_filename)
    pixnet_filename_after = "converted_pixnet_data_after/*.json"
    pixnet_each_after = glob.glob(pixnet_filename_after)
    content_filename = "pixnet_content/*.csv"
    content_each = glob.glob(content_filename)
    file_index = 0
    #define a dict for counted data
    count_data = dict()

    #for file_name in attributes_each :

    #    #convert csv to json
    #    convert_to_json_attributes(file_name)

    #    #fetch and get each document of ppt_japan_data
    #    fetch_data_attributes("converted_pixnet_data/"+file_name[18:-4]+".json")

    for file_name in content_each :

        #convert csv to json
        #convert_to_json_content(file_name)

        #fetch and get each document of ppt_japan_data
        #print(pixnet_each_after)
        fetch_data_content_after("converted_pixnet_data/"+file_name[15:-4]+".json",pixnet_each_after[file_index])
        file_index += 1
